{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc3febc-4968-44dc-abd3-c92ce75f9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/home/alexanderalbizu\")\n",
    "sys.path.append(\"/home/alexanderalbizu/.local/bin\")\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"CNN.ipynb\"\n",
    "#!python setup.py develop \n",
    "# !pip install wandb\n",
    "# !pip install 'monai[all]'\n",
    "#!pip -q install vit_pytorch\n",
    "#!pip -q install linformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be71323-075d-4572-9b67-5e255af752de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.1+331.g6a301d51.dirty\n",
      "Numpy version: 1.20.1\n",
      "Pytorch version: 1.9.0+cu111\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 6a301d51fbbb1803b7349a85c9bfa398f19ee0f9\n",
      "MONAI __file__: /home/alexanderalbizu/MONAI/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.19.1\n",
      "Pillow version: 9.1.1\n",
      "Tensorboard version: 1.15.0+nv\n",
      "gdown version: 4.4.0\n",
      "TorchVision version: 0.10.0+cu111\n",
      "tqdm version: 4.53.0\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.1.4\n",
      "einops version: 0.4.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: 1.26.1\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maalbizu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import glob, math, os, shutil, tempfile, time, monai, torch, random\n",
    "\n",
    "import wandb as wb\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.networks.utils import eval_mode\n",
    "from monai.config import print_config\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    ThreadDataLoader,\n",
    "    ImageDataset,\n",
    "    Dataset,\n",
    "    decollate_batch,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.layers import Act, Norm\n",
    "from monai.transforms import (\n",
    "    AddChannel,\n",
    "    AsChannelFirst,\n",
    "    Compose,\n",
    "    RandGaussianNoise,\n",
    "    Resize,\n",
    "    RemoveRepeatedChannel,\n",
    "    Orientation,\n",
    "    RandRotate90,\n",
    "    RandBiasField,\n",
    "    ScaleIntensity,\n",
    "    ToDevice,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print_config()\n",
    "wb.login(); # 7e5f63e5846f29b034d98806712ab047df76834d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbded201-a325-4627-86e5-14bcaceac6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/alexanderalbizu/MONAI/wandb/run-20220706_000657-8k1qzznx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/aalbizu/SMART-CNN-2D_II/runs/8k1qzznx\" target=\"_blank\">apricot-violet-30</a></strong> to <a href=\"https://wandb.ai/aalbizu/SMART-CNN-2D_II\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Fold  1\n",
      "test subs:  [9048 9045]\n",
      "valid subs:  [9044 9054]\n",
      "train case split:  404 : 606\n",
      "valid case split:  101 : 101\n",
      "test case split:  202 : 0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 - train_loss : 0.6699 - train_acc: 0.5974 - val_loss : 0.6934 - val_acc: 0.5491\n",
      "\n",
      "model saved\n",
      "Epoch : 2 - train_loss : 0.6128 - train_acc: 0.7045 - val_loss : 0.7236 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 3 - train_loss : 0.5391 - train_acc: 0.7785 - val_loss : 0.7355 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 4 - train_loss : 0.4280 - train_acc: 0.8698 - val_loss : 0.7410 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 5 - train_loss : 0.3261 - train_acc: 0.8981 - val_loss : 0.7979 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 6 - train_loss : 0.2226 - train_acc: 0.9680 - val_loss : 0.9188 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 7 - train_loss : 0.1874 - train_acc: 0.9805 - val_loss : 0.9319 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 8 - train_loss : 0.1532 - train_acc: 0.9873 - val_loss : 1.1065 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 9 - train_loss : 0.1217 - train_acc: 0.9961 - val_loss : 1.1069 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 10 - train_loss : 0.1219 - train_acc: 0.9922 - val_loss : 0.9442 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 11 - train_loss : 0.0940 - train_acc: 0.9971 - val_loss : 1.1692 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 12 - train_loss : 0.0922 - train_acc: 1.0000 - val_loss : 1.2923 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 13 - train_loss : 0.0934 - train_acc: 0.9932 - val_loss : 1.0594 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 14 - train_loss : 0.0780 - train_acc: 0.9980 - val_loss : 1.3014 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 15 - train_loss : 0.0736 - train_acc: 0.9971 - val_loss : 1.3315 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 16 - train_loss : 0.0597 - train_acc: 1.0000 - val_loss : 1.4457 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 17 - train_loss : 0.0612 - train_acc: 0.9980 - val_loss : 1.5644 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 18 - train_loss : 0.0579 - train_acc: 1.0000 - val_loss : 1.6346 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 19 - train_loss : 0.0570 - train_acc: 0.9983 - val_loss : 1.6299 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 20 - train_loss : 0.0627 - train_acc: 0.9951 - val_loss : 1.6756 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 21 - train_loss : 0.0516 - train_acc: 0.9990 - val_loss : 1.7563 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 22 - train_loss : 0.0463 - train_acc: 1.0000 - val_loss : 1.5648 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 23 - train_loss : 0.0417 - train_acc: 1.0000 - val_loss : 1.4963 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 24 - train_loss : 0.0393 - train_acc: 1.0000 - val_loss : 1.8461 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 25 - train_loss : 0.0350 - train_acc: 0.9990 - val_loss : 1.6515 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 26 - train_loss : 0.0339 - train_acc: 1.0000 - val_loss : 1.7772 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 27 - train_loss : 0.0318 - train_acc: 1.0000 - val_loss : 1.7942 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 28 - train_loss : 0.0374 - train_acc: 0.9971 - val_loss : 1.8392 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 29 - train_loss : 0.0388 - train_acc: 0.9971 - val_loss : 1.8656 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 30 - train_loss : 0.0307 - train_acc: 1.0000 - val_loss : 1.8136 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 31 - train_loss : 0.0263 - train_acc: 1.0000 - val_loss : 2.0079 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 32 - train_loss : 0.0272 - train_acc: 1.0000 - val_loss : 1.9357 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 33 - train_loss : 0.0308 - train_acc: 1.0000 - val_loss : 2.0136 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 34 - train_loss : 0.0206 - train_acc: 1.0000 - val_loss : 2.0016 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 35 - train_loss : 0.0246 - train_acc: 1.0000 - val_loss : 1.9302 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 36 - train_loss : 0.0240 - train_acc: 1.0000 - val_loss : 2.1405 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 37 - train_loss : 0.0196 - train_acc: 1.0000 - val_loss : 2.1781 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 38 - train_loss : 0.0199 - train_acc: 1.0000 - val_loss : 1.9278 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 39 - train_loss : 0.0227 - train_acc: 1.0000 - val_loss : 2.4122 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 40 - train_loss : 0.0178 - train_acc: 1.0000 - val_loss : 2.1491 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 41 - train_loss : 0.0164 - train_acc: 1.0000 - val_loss : 2.1380 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 42 - train_loss : 0.0132 - train_acc: 1.0000 - val_loss : 2.1606 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 43 - train_loss : 0.0166 - train_acc: 1.0000 - val_loss : 2.2702 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 44 - train_loss : 0.0137 - train_acc: 1.0000 - val_loss : 2.2991 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 45 - train_loss : 0.0136 - train_acc: 1.0000 - val_loss : 2.2854 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 46 - train_loss : 0.0122 - train_acc: 1.0000 - val_loss : 2.3209 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 47 - train_loss : 0.0105 - train_acc: 1.0000 - val_loss : 2.4804 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 48 - train_loss : 0.0113 - train_acc: 1.0000 - val_loss : 2.4834 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 49 - train_loss : 0.0130 - train_acc: 1.0000 - val_loss : 2.3324 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 50 - train_loss : 0.0102 - train_acc: 1.0000 - val_loss : 2.5380 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 51 - train_loss : 0.0120 - train_acc: 1.0000 - val_loss : 2.7866 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 52 - train_loss : 0.0096 - train_acc: 1.0000 - val_loss : 2.2977 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 53 - train_loss : 0.0091 - train_acc: 1.0000 - val_loss : 2.3737 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 54 - train_loss : 0.0109 - train_acc: 1.0000 - val_loss : 2.2575 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 55 - train_loss : 0.0094 - train_acc: 1.0000 - val_loss : 2.5291 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 56 - train_loss : 0.0157 - train_acc: 0.9990 - val_loss : 2.3878 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 57 - train_loss : 0.0076 - train_acc: 1.0000 - val_loss : 2.6206 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 58 - train_loss : 0.0072 - train_acc: 1.0000 - val_loss : 2.8730 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 59 - train_loss : 0.0067 - train_acc: 1.0000 - val_loss : 2.5858 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 60 - train_loss : 0.0098 - train_acc: 1.0000 - val_loss : 2.2538 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 61 - train_loss : 0.0072 - train_acc: 1.0000 - val_loss : 2.5881 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 62 - train_loss : 0.0062 - train_acc: 1.0000 - val_loss : 2.4390 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 63 - train_loss : 0.0067 - train_acc: 1.0000 - val_loss : 2.7118 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 64 - train_loss : 0.0074 - train_acc: 1.0000 - val_loss : 2.9655 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 65 - train_loss : 0.0077 - train_acc: 1.0000 - val_loss : 2.9088 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 66 - train_loss : 0.0093 - train_acc: 1.0000 - val_loss : 2.6447 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 67 - train_loss : 0.0070 - train_acc: 1.0000 - val_loss : 2.9204 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 68 - train_loss : 0.0094 - train_acc: 0.9980 - val_loss : 2.5354 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 69 - train_loss : 0.0053 - train_acc: 1.0000 - val_loss : 2.7922 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 70 - train_loss : 0.0080 - train_acc: 1.0000 - val_loss : 3.2685 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 71 - train_loss : 0.0097 - train_acc: 0.9990 - val_loss : 2.6578 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 72 - train_loss : 0.0095 - train_acc: 1.0000 - val_loss : 3.0116 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 73 - train_loss : 0.0078 - train_acc: 1.0000 - val_loss : 2.8089 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 74 - train_loss : 0.0042 - train_acc: 1.0000 - val_loss : 2.7185 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 75 - train_loss : 0.0094 - train_acc: 0.9980 - val_loss : 2.9919 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 76 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 2.5326 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 77 - train_loss : 0.0033 - train_acc: 1.0000 - val_loss : 2.9219 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 78 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 2.7125 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 79 - train_loss : 0.0045 - train_acc: 1.0000 - val_loss : 2.7551 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 80 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 2.9904 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 81 - train_loss : 0.0035 - train_acc: 1.0000 - val_loss : 2.7065 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 82 - train_loss : 0.0058 - train_acc: 1.0000 - val_loss : 3.1385 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 83 - train_loss : 0.0047 - train_acc: 1.0000 - val_loss : 2.6901 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 84 - train_loss : 0.0037 - train_acc: 1.0000 - val_loss : 3.1505 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 85 - train_loss : 0.0033 - train_acc: 1.0000 - val_loss : 2.6301 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 86 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 2.7217 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 87 - train_loss : 0.0029 - train_acc: 1.0000 - val_loss : 2.9097 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 88 - train_loss : 0.0030 - train_acc: 1.0000 - val_loss : 3.1366 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 89 - train_loss : 0.0039 - train_acc: 1.0000 - val_loss : 2.9545 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 90 - train_loss : 0.0037 - train_acc: 1.0000 - val_loss : 3.0416 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 91 - train_loss : 0.0028 - train_acc: 1.0000 - val_loss : 3.0960 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 92 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 2.9725 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 93 - train_loss : 0.0038 - train_acc: 1.0000 - val_loss : 2.9111 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 94 - train_loss : 0.0043 - train_acc: 1.0000 - val_loss : 3.0309 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 95 - train_loss : 0.0043 - train_acc: 1.0000 - val_loss : 2.8776 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 96 - train_loss : 0.0033 - train_acc: 1.0000 - val_loss : 3.2498 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 97 - train_loss : 0.0032 - train_acc: 1.0000 - val_loss : 3.3133 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 98 - train_loss : 0.0022 - train_acc: 1.0000 - val_loss : 3.2913 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 99 - train_loss : 0.0021 - train_acc: 1.0000 - val_loss : 2.6882 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 100 - train_loss : 0.0019 - train_acc: 1.0000 - val_loss : 3.1167 - val_acc: 0.5491\n",
      "\n",
      "Fold 1 Test Accuracy:  tensor(0.0045, device='cuda:0')\n",
      "Beginning Fold  2\n",
      "test subs:  [9040 9054]\n",
      "valid subs:  [9031 9045]\n",
      "train case split:  505 : 505\n",
      "valid case split:  101 : 101\n",
      "test case split:  101 : 101 \n",
      "\n",
      "Epoch : 1 - train_loss : 0.6503 - train_acc: 0.6229 - val_loss : 0.8311 - val_acc: 0.5491\n",
      "\n",
      "model saved\n",
      "Epoch : 2 - train_loss : 0.5824 - train_acc: 0.6964 - val_loss : 0.9450 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 3 - train_loss : 0.5042 - train_acc: 0.7766 - val_loss : 1.1228 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 4 - train_loss : 0.4132 - train_acc: 0.8698 - val_loss : 1.7879 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 5 - train_loss : 0.3164 - train_acc: 0.8959 - val_loss : 2.4538 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 6 - train_loss : 0.2437 - train_acc: 0.9404 - val_loss : 2.8790 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 7 - train_loss : 0.1860 - train_acc: 0.9854 - val_loss : 3.3299 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 8 - train_loss : 0.1617 - train_acc: 0.9883 - val_loss : 3.8874 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 9 - train_loss : 0.1394 - train_acc: 0.9932 - val_loss : 3.8538 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 10 - train_loss : 0.1166 - train_acc: 0.9941 - val_loss : 4.2035 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 11 - train_loss : 0.1003 - train_acc: 0.9980 - val_loss : 4.5917 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 12 - train_loss : 0.1041 - train_acc: 0.9946 - val_loss : 4.4590 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 13 - train_loss : 0.1014 - train_acc: 0.9902 - val_loss : 4.5877 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 14 - train_loss : 0.0812 - train_acc: 0.9951 - val_loss : 5.3119 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 15 - train_loss : 0.0836 - train_acc: 0.9971 - val_loss : 5.3375 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 16 - train_loss : 0.0742 - train_acc: 0.9980 - val_loss : 5.8466 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 17 - train_loss : 0.0746 - train_acc: 0.9973 - val_loss : 5.9688 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 18 - train_loss : 0.0659 - train_acc: 0.9980 - val_loss : 5.6931 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 19 - train_loss : 0.0568 - train_acc: 0.9983 - val_loss : 6.3733 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 20 - train_loss : 0.0515 - train_acc: 0.9983 - val_loss : 5.6208 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 21 - train_loss : 0.0490 - train_acc: 1.0000 - val_loss : 6.3275 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 22 - train_loss : 0.0422 - train_acc: 1.0000 - val_loss : 6.5212 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 23 - train_loss : 0.0516 - train_acc: 0.9951 - val_loss : 6.8315 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 24 - train_loss : 0.0606 - train_acc: 0.9932 - val_loss : 6.1516 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 25 - train_loss : 0.0494 - train_acc: 0.9990 - val_loss : 7.0875 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 26 - train_loss : 0.0436 - train_acc: 0.9990 - val_loss : 6.4982 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 27 - train_loss : 0.0380 - train_acc: 1.0000 - val_loss : 7.4205 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 28 - train_loss : 0.0376 - train_acc: 1.0000 - val_loss : 7.0414 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 29 - train_loss : 0.0303 - train_acc: 1.0000 - val_loss : 7.4691 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 30 - train_loss : 0.0298 - train_acc: 1.0000 - val_loss : 7.2766 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 31 - train_loss : 0.0283 - train_acc: 1.0000 - val_loss : 7.1541 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 32 - train_loss : 0.0313 - train_acc: 1.0000 - val_loss : 7.2070 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 33 - train_loss : 0.0262 - train_acc: 1.0000 - val_loss : 7.4823 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 34 - train_loss : 0.0353 - train_acc: 0.9971 - val_loss : 7.0852 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 35 - train_loss : 0.0247 - train_acc: 1.0000 - val_loss : 7.8689 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 36 - train_loss : 0.0231 - train_acc: 1.0000 - val_loss : 7.5714 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 37 - train_loss : 0.0207 - train_acc: 1.0000 - val_loss : 8.1739 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 38 - train_loss : 0.0190 - train_acc: 1.0000 - val_loss : 6.8716 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 39 - train_loss : 0.0201 - train_acc: 1.0000 - val_loss : 8.6136 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 40 - train_loss : 0.0180 - train_acc: 1.0000 - val_loss : 7.3013 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 41 - train_loss : 0.0154 - train_acc: 1.0000 - val_loss : 8.2026 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 42 - train_loss : 0.0154 - train_acc: 1.0000 - val_loss : 8.2332 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 43 - train_loss : 0.0145 - train_acc: 1.0000 - val_loss : 8.0567 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 44 - train_loss : 0.0147 - train_acc: 1.0000 - val_loss : 8.7186 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 45 - train_loss : 0.0183 - train_acc: 1.0000 - val_loss : 8.2325 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 46 - train_loss : 0.0118 - train_acc: 1.0000 - val_loss : 8.0130 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 47 - train_loss : 0.0156 - train_acc: 1.0000 - val_loss : 8.5378 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 48 - train_loss : 0.0142 - train_acc: 1.0000 - val_loss : 7.7234 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 49 - train_loss : 0.0142 - train_acc: 1.0000 - val_loss : 8.7897 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 50 - train_loss : 0.0122 - train_acc: 1.0000 - val_loss : 8.3856 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 51 - train_loss : 0.0093 - train_acc: 1.0000 - val_loss : 8.6657 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 52 - train_loss : 0.0098 - train_acc: 1.0000 - val_loss : 8.1088 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 53 - train_loss : 0.0099 - train_acc: 1.0000 - val_loss : 8.9254 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 54 - train_loss : 0.0115 - train_acc: 1.0000 - val_loss : 9.2199 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 55 - train_loss : 0.0111 - train_acc: 0.9983 - val_loss : 9.0994 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 56 - train_loss : 0.0126 - train_acc: 1.0000 - val_loss : 9.2850 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 57 - train_loss : 0.0114 - train_acc: 1.0000 - val_loss : 8.8119 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 58 - train_loss : 0.0072 - train_acc: 1.0000 - val_loss : 8.9475 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 59 - train_loss : 0.0080 - train_acc: 1.0000 - val_loss : 8.0436 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 60 - train_loss : 0.0068 - train_acc: 1.0000 - val_loss : 9.4789 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 61 - train_loss : 0.0077 - train_acc: 1.0000 - val_loss : 9.6603 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 62 - train_loss : 0.0073 - train_acc: 1.0000 - val_loss : 9.5037 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 63 - train_loss : 0.0076 - train_acc: 1.0000 - val_loss : 9.2611 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 64 - train_loss : 0.0061 - train_acc: 1.0000 - val_loss : 8.6525 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 65 - train_loss : 0.0083 - train_acc: 1.0000 - val_loss : 9.2361 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 66 - train_loss : 0.0088 - train_acc: 1.0000 - val_loss : 9.3127 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 67 - train_loss : 0.0069 - train_acc: 1.0000 - val_loss : 10.5200 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 68 - train_loss : 0.0059 - train_acc: 1.0000 - val_loss : 10.2754 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 69 - train_loss : 0.0055 - train_acc: 1.0000 - val_loss : 10.6665 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 70 - train_loss : 0.0069 - train_acc: 1.0000 - val_loss : 10.8433 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 71 - train_loss : 0.0051 - train_acc: 1.0000 - val_loss : 9.3705 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 72 - train_loss : 0.0053 - train_acc: 1.0000 - val_loss : 9.3663 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 73 - train_loss : 0.0047 - train_acc: 1.0000 - val_loss : 10.2309 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 74 - train_loss : 0.0059 - train_acc: 1.0000 - val_loss : 9.7430 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 75 - train_loss : 0.0047 - train_acc: 1.0000 - val_loss : 11.3135 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 76 - train_loss : 0.0087 - train_acc: 0.9980 - val_loss : 9.1955 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 77 - train_loss : 0.0046 - train_acc: 1.0000 - val_loss : 11.3692 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 78 - train_loss : 0.0051 - train_acc: 1.0000 - val_loss : 11.9390 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 79 - train_loss : 0.0054 - train_acc: 1.0000 - val_loss : 10.3634 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 80 - train_loss : 0.0043 - train_acc: 1.0000 - val_loss : 10.3954 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 81 - train_loss : 0.0040 - train_acc: 1.0000 - val_loss : 10.3257 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 82 - train_loss : 0.0053 - train_acc: 1.0000 - val_loss : 8.5268 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 83 - train_loss : 0.0045 - train_acc: 1.0000 - val_loss : 10.9520 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 84 - train_loss : 0.0033 - train_acc: 1.0000 - val_loss : 9.8887 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 85 - train_loss : 0.0034 - train_acc: 1.0000 - val_loss : 10.2313 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 86 - train_loss : 0.0041 - train_acc: 1.0000 - val_loss : 10.1862 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 87 - train_loss : 0.0040 - train_acc: 1.0000 - val_loss : 11.2066 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 88 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 9.8016 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 89 - train_loss : 0.0034 - train_acc: 1.0000 - val_loss : 10.0204 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 90 - train_loss : 0.0079 - train_acc: 0.9983 - val_loss : 10.4661 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 91 - train_loss : 0.0068 - train_acc: 1.0000 - val_loss : 11.8362 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 92 - train_loss : 0.0032 - train_acc: 1.0000 - val_loss : 11.4989 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 93 - train_loss : 0.0041 - train_acc: 1.0000 - val_loss : 12.3422 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 94 - train_loss : 0.0034 - train_acc: 1.0000 - val_loss : 10.7010 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 95 - train_loss : 0.0030 - train_acc: 1.0000 - val_loss : 12.0163 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 96 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 9.8939 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 97 - train_loss : 0.0039 - train_acc: 0.9990 - val_loss : 10.4422 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 98 - train_loss : 0.0037 - train_acc: 1.0000 - val_loss : 12.1499 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 99 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 11.0300 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 100 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 11.3048 - val_acc: 0.0000\n",
      "\n",
      "Fold 2 Test Accuracy:  tensor(0.4170, device='cuda:0')\n",
      "Beginning Fold  3\n",
      "test subs:  [9009 9015]\n",
      "valid subs:  [9048 9054]\n",
      "train case split:  404 : 606\n",
      "valid case split:  101 : 101\n",
      "test case split:  202 : 0 \n",
      "\n",
      "Epoch : 1 - train_loss : 0.6349 - train_acc: 0.6769 - val_loss : 0.7659 - val_acc: 0.5491\n",
      "\n",
      "model saved\n",
      "Epoch : 2 - train_loss : 0.5355 - train_acc: 0.7667 - val_loss : 0.9444 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 3 - train_loss : 0.4547 - train_acc: 0.8247 - val_loss : 1.0664 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 4 - train_loss : 0.3767 - train_acc: 0.8516 - val_loss : 1.2423 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 5 - train_loss : 0.3011 - train_acc: 0.8869 - val_loss : 1.2109 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 6 - train_loss : 0.2513 - train_acc: 0.9355 - val_loss : 1.3925 - val_acc: 0.3223\n",
      "\n",
      "Epoch : 7 - train_loss : 0.1956 - train_acc: 0.9502 - val_loss : 1.2791 - val_acc: 0.5089\n",
      "\n",
      "Epoch : 8 - train_loss : 0.1610 - train_acc: 0.9795 - val_loss : 1.2754 - val_acc: 0.5357\n",
      "\n",
      "Epoch : 9 - train_loss : 0.1328 - train_acc: 0.9926 - val_loss : 1.1280 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 10 - train_loss : 0.1300 - train_acc: 0.9844 - val_loss : 1.0569 - val_acc: 0.5312\n",
      "\n",
      "Epoch : 11 - train_loss : 0.1079 - train_acc: 0.9946 - val_loss : 1.3027 - val_acc: 0.5402\n",
      "\n",
      "Epoch : 12 - train_loss : 0.0955 - train_acc: 0.9932 - val_loss : 1.2512 - val_acc: 0.3723\n",
      "\n",
      "Epoch : 13 - train_loss : 0.0800 - train_acc: 0.9971 - val_loss : 1.2456 - val_acc: 0.5402\n",
      "\n",
      "Epoch : 14 - train_loss : 0.0800 - train_acc: 0.9990 - val_loss : 1.3677 - val_acc: 0.5446\n",
      "\n",
      "Epoch : 15 - train_loss : 0.0684 - train_acc: 1.0000 - val_loss : 1.6716 - val_acc: 0.3705\n",
      "\n",
      "Epoch : 16 - train_loss : 0.0624 - train_acc: 0.9971 - val_loss : 1.3383 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 17 - train_loss : 0.0685 - train_acc: 0.9980 - val_loss : 1.4424 - val_acc: 0.4777\n",
      "\n",
      "Epoch : 18 - train_loss : 0.0525 - train_acc: 1.0000 - val_loss : 1.6255 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 19 - train_loss : 0.0509 - train_acc: 1.0000 - val_loss : 1.4149 - val_acc: 0.5446\n",
      "\n",
      "Epoch : 20 - train_loss : 0.0465 - train_acc: 1.0000 - val_loss : 1.5516 - val_acc: 0.5402\n",
      "\n",
      "Epoch : 21 - train_loss : 0.0452 - train_acc: 1.0000 - val_loss : 1.4715 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 22 - train_loss : 0.0529 - train_acc: 0.9961 - val_loss : 1.5941 - val_acc: 0.5000\n",
      "\n",
      "Epoch : 23 - train_loss : 0.0408 - train_acc: 1.0000 - val_loss : 1.7304 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 24 - train_loss : 0.0368 - train_acc: 1.0000 - val_loss : 1.6463 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 25 - train_loss : 0.0411 - train_acc: 1.0000 - val_loss : 1.8022 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 26 - train_loss : 0.0409 - train_acc: 1.0000 - val_loss : 1.6803 - val_acc: 0.5446\n",
      "\n",
      "Epoch : 27 - train_loss : 0.0391 - train_acc: 1.0000 - val_loss : 1.8448 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 28 - train_loss : 0.0303 - train_acc: 1.0000 - val_loss : 1.8678 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 29 - train_loss : 0.0289 - train_acc: 1.0000 - val_loss : 1.7189 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 30 - train_loss : 0.0265 - train_acc: 1.0000 - val_loss : 1.9530 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 31 - train_loss : 0.0232 - train_acc: 1.0000 - val_loss : 1.8823 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 32 - train_loss : 0.0240 - train_acc: 1.0000 - val_loss : 1.9726 - val_acc: 0.5446\n",
      "\n",
      "Epoch : 33 - train_loss : 0.0231 - train_acc: 1.0000 - val_loss : 2.1577 - val_acc: 0.5045\n",
      "\n",
      "Epoch : 34 - train_loss : 0.0192 - train_acc: 1.0000 - val_loss : 2.1198 - val_acc: 0.5089\n",
      "\n",
      "Epoch : 35 - train_loss : 0.0209 - train_acc: 1.0000 - val_loss : 2.0749 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 36 - train_loss : 0.0222 - train_acc: 1.0000 - val_loss : 2.0214 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 37 - train_loss : 0.0218 - train_acc: 1.0000 - val_loss : 1.8985 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 38 - train_loss : 0.0210 - train_acc: 1.0000 - val_loss : 1.9603 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 39 - train_loss : 0.0190 - train_acc: 1.0000 - val_loss : 2.4229 - val_acc: 0.5268\n",
      "\n",
      "Epoch : 40 - train_loss : 0.0156 - train_acc: 1.0000 - val_loss : 2.2275 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 41 - train_loss : 0.0173 - train_acc: 0.9990 - val_loss : 2.0695 - val_acc: 0.5446\n",
      "\n",
      "Epoch : 42 - train_loss : 0.0145 - train_acc: 1.0000 - val_loss : 2.2619 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 43 - train_loss : 0.0153 - train_acc: 1.0000 - val_loss : 2.3883 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 44 - train_loss : 0.0140 - train_acc: 1.0000 - val_loss : 2.2847 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 45 - train_loss : 0.0261 - train_acc: 0.9913 - val_loss : 2.0256 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 46 - train_loss : 0.0143 - train_acc: 1.0000 - val_loss : 2.2154 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 47 - train_loss : 0.0139 - train_acc: 1.0000 - val_loss : 2.3206 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 48 - train_loss : 0.0132 - train_acc: 1.0000 - val_loss : 2.2908 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 49 - train_loss : 0.0134 - train_acc: 0.9983 - val_loss : 2.4339 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 50 - train_loss : 0.0137 - train_acc: 1.0000 - val_loss : 2.2729 - val_acc: 0.5223\n",
      "\n",
      "Epoch : 51 - train_loss : 0.0115 - train_acc: 1.0000 - val_loss : 2.2992 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 52 - train_loss : 0.0100 - train_acc: 1.0000 - val_loss : 2.4850 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 53 - train_loss : 0.0095 - train_acc: 1.0000 - val_loss : 2.3580 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 54 - train_loss : 0.0113 - train_acc: 1.0000 - val_loss : 2.6747 - val_acc: 0.5134\n",
      "\n",
      "Epoch : 55 - train_loss : 0.0104 - train_acc: 1.0000 - val_loss : 2.4059 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 56 - train_loss : 0.0118 - train_acc: 0.9983 - val_loss : 2.5875 - val_acc: 0.5402\n",
      "\n",
      "Epoch : 57 - train_loss : 0.0096 - train_acc: 1.0000 - val_loss : 2.4725 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 58 - train_loss : 0.0070 - train_acc: 1.0000 - val_loss : 2.5008 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 59 - train_loss : 0.0070 - train_acc: 1.0000 - val_loss : 2.6179 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 60 - train_loss : 0.0070 - train_acc: 1.0000 - val_loss : 2.5832 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 61 - train_loss : 0.0080 - train_acc: 1.0000 - val_loss : 2.7063 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 62 - train_loss : 0.0063 - train_acc: 1.0000 - val_loss : 2.7800 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 63 - train_loss : 0.0060 - train_acc: 1.0000 - val_loss : 2.7157 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 64 - train_loss : 0.0092 - train_acc: 1.0000 - val_loss : 2.6459 - val_acc: 0.5446\n",
      "\n",
      "Epoch : 65 - train_loss : 0.0057 - train_acc: 1.0000 - val_loss : 2.5969 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 66 - train_loss : 0.0080 - train_acc: 0.9983 - val_loss : 2.7560 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 67 - train_loss : 0.0076 - train_acc: 1.0000 - val_loss : 2.2771 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 68 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 2.5964 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 69 - train_loss : 0.0058 - train_acc: 1.0000 - val_loss : 2.7738 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 70 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 2.8445 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 71 - train_loss : 0.0047 - train_acc: 1.0000 - val_loss : 2.8295 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 72 - train_loss : 0.0071 - train_acc: 1.0000 - val_loss : 2.7878 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 73 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 2.7211 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 74 - train_loss : 0.0044 - train_acc: 1.0000 - val_loss : 2.8306 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 75 - train_loss : 0.0044 - train_acc: 1.0000 - val_loss : 2.8228 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 76 - train_loss : 0.0043 - train_acc: 1.0000 - val_loss : 2.9248 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 77 - train_loss : 0.0039 - train_acc: 1.0000 - val_loss : 3.0322 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 78 - train_loss : 0.0035 - train_acc: 1.0000 - val_loss : 2.9591 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 79 - train_loss : 0.0049 - train_acc: 1.0000 - val_loss : 2.9585 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 80 - train_loss : 0.0061 - train_acc: 1.0000 - val_loss : 2.8511 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 81 - train_loss : 0.0037 - train_acc: 1.0000 - val_loss : 2.9216 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 82 - train_loss : 0.0037 - train_acc: 1.0000 - val_loss : 3.0074 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 83 - train_loss : 0.0032 - train_acc: 1.0000 - val_loss : 3.0272 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 84 - train_loss : 0.0042 - train_acc: 1.0000 - val_loss : 3.0716 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 85 - train_loss : 0.0049 - train_acc: 1.0000 - val_loss : 2.8522 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 86 - train_loss : 0.0036 - train_acc: 1.0000 - val_loss : 2.9467 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 87 - train_loss : 0.0026 - train_acc: 1.0000 - val_loss : 2.8695 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 88 - train_loss : 0.0032 - train_acc: 1.0000 - val_loss : 3.0396 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 89 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 2.9508 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 90 - train_loss : 0.0036 - train_acc: 1.0000 - val_loss : 3.1667 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 91 - train_loss : 0.0031 - train_acc: 1.0000 - val_loss : 3.3134 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 92 - train_loss : 0.0033 - train_acc: 1.0000 - val_loss : 2.9358 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 93 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 3.2830 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 94 - train_loss : 0.0021 - train_acc: 1.0000 - val_loss : 3.0834 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 95 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 3.2689 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 96 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 3.3239 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 97 - train_loss : 0.0124 - train_acc: 1.0000 - val_loss : 3.4071 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 98 - train_loss : 0.0034 - train_acc: 1.0000 - val_loss : 3.0504 - val_acc: 0.5179\n",
      "\n",
      "Epoch : 99 - train_loss : 0.0024 - train_acc: 1.0000 - val_loss : 2.8948 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 100 - train_loss : 0.0024 - train_acc: 1.0000 - val_loss : 2.9977 - val_acc: 0.5491\n",
      "\n",
      "Fold 3 Test Accuracy:  tensor(0., device='cuda:0')\n",
      "Beginning Fold  4\n",
      "test subs:  [9031 9022]\n",
      "valid subs:  [9032 9045]\n",
      "train case split:  505 : 505\n",
      "valid case split:  101 : 101\n",
      "test case split:  101 : 101 \n",
      "\n",
      "Epoch : 1 - train_loss : 0.6690 - train_acc: 0.6075 - val_loss : 0.9596 - val_acc: 0.0000\n",
      "\n",
      "model saved\n",
      "Epoch : 2 - train_loss : 0.5864 - train_acc: 0.7775 - val_loss : 1.7816 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 3 - train_loss : 0.4798 - train_acc: 0.7985 - val_loss : 2.8249 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 4 - train_loss : 0.3593 - train_acc: 0.9463 - val_loss : 3.7404 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 5 - train_loss : 0.2397 - train_acc: 0.9746 - val_loss : 4.5585 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 6 - train_loss : 0.1741 - train_acc: 0.9897 - val_loss : 5.5054 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 7 - train_loss : 0.1342 - train_acc: 0.9924 - val_loss : 5.4231 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 8 - train_loss : 0.1218 - train_acc: 0.9916 - val_loss : 5.3026 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 9 - train_loss : 0.1008 - train_acc: 0.9990 - val_loss : 5.7363 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 10 - train_loss : 0.0919 - train_acc: 1.0000 - val_loss : 5.4651 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 11 - train_loss : 0.0883 - train_acc: 0.9961 - val_loss : 6.1952 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 12 - train_loss : 0.0880 - train_acc: 0.9953 - val_loss : 6.0602 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 13 - train_loss : 0.0719 - train_acc: 0.9980 - val_loss : 6.1396 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 14 - train_loss : 0.0643 - train_acc: 1.0000 - val_loss : 5.9321 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 15 - train_loss : 0.0630 - train_acc: 0.9980 - val_loss : 6.1082 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 16 - train_loss : 0.0570 - train_acc: 1.0000 - val_loss : 6.5695 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 17 - train_loss : 0.0579 - train_acc: 0.9971 - val_loss : 6.3847 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 18 - train_loss : 0.0549 - train_acc: 1.0000 - val_loss : 6.7832 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 19 - train_loss : 0.0568 - train_acc: 0.9922 - val_loss : 5.8415 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 20 - train_loss : 0.0441 - train_acc: 0.9980 - val_loss : 6.4642 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 21 - train_loss : 0.0559 - train_acc: 0.9941 - val_loss : 6.6013 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 22 - train_loss : 0.0406 - train_acc: 1.0000 - val_loss : 6.4361 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 23 - train_loss : 0.0381 - train_acc: 0.9990 - val_loss : 6.6938 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 24 - train_loss : 0.0352 - train_acc: 1.0000 - val_loss : 7.0708 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 25 - train_loss : 0.0317 - train_acc: 1.0000 - val_loss : 6.5109 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 26 - train_loss : 0.0305 - train_acc: 1.0000 - val_loss : 6.7959 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 27 - train_loss : 0.0290 - train_acc: 1.0000 - val_loss : 6.8039 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 28 - train_loss : 0.0274 - train_acc: 1.0000 - val_loss : 7.1583 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 29 - train_loss : 0.0230 - train_acc: 1.0000 - val_loss : 7.0267 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 30 - train_loss : 0.0263 - train_acc: 0.9990 - val_loss : 7.1513 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 31 - train_loss : 0.0257 - train_acc: 0.9983 - val_loss : 7.7199 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 32 - train_loss : 0.0238 - train_acc: 1.0000 - val_loss : 7.8680 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 33 - train_loss : 0.0194 - train_acc: 1.0000 - val_loss : 7.8140 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 34 - train_loss : 0.0188 - train_acc: 1.0000 - val_loss : 7.7605 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 35 - train_loss : 0.0170 - train_acc: 1.0000 - val_loss : 7.8985 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 36 - train_loss : 0.0166 - train_acc: 1.0000 - val_loss : 7.9521 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 37 - train_loss : 0.0230 - train_acc: 0.9951 - val_loss : 7.3581 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 38 - train_loss : 0.0201 - train_acc: 1.0000 - val_loss : 8.1814 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 39 - train_loss : 0.0151 - train_acc: 1.0000 - val_loss : 7.8923 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 40 - train_loss : 0.0124 - train_acc: 1.0000 - val_loss : 8.6137 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 41 - train_loss : 0.0142 - train_acc: 1.0000 - val_loss : 7.8640 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 42 - train_loss : 0.0117 - train_acc: 1.0000 - val_loss : 8.0368 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 43 - train_loss : 0.0159 - train_acc: 0.9990 - val_loss : 8.6099 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 44 - train_loss : 0.0113 - train_acc: 1.0000 - val_loss : 8.3039 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 45 - train_loss : 0.0117 - train_acc: 1.0000 - val_loss : 8.5693 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 46 - train_loss : 0.0106 - train_acc: 0.9990 - val_loss : 8.7367 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 47 - train_loss : 0.0103 - train_acc: 1.0000 - val_loss : 8.4157 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 48 - train_loss : 0.0128 - train_acc: 1.0000 - val_loss : 8.6573 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 49 - train_loss : 0.0118 - train_acc: 1.0000 - val_loss : 7.9195 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 50 - train_loss : 0.0146 - train_acc: 0.9961 - val_loss : 9.2504 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 51 - train_loss : 0.0115 - train_acc: 1.0000 - val_loss : 8.5810 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 52 - train_loss : 0.0085 - train_acc: 1.0000 - val_loss : 8.3181 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 53 - train_loss : 0.0074 - train_acc: 1.0000 - val_loss : 8.9637 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 54 - train_loss : 0.0057 - train_acc: 1.0000 - val_loss : 8.7751 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 55 - train_loss : 0.0089 - train_acc: 1.0000 - val_loss : 9.4170 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 56 - train_loss : 0.0096 - train_acc: 1.0000 - val_loss : 9.1050 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 57 - train_loss : 0.0060 - train_acc: 1.0000 - val_loss : 8.4399 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 58 - train_loss : 0.0065 - train_acc: 1.0000 - val_loss : 8.9563 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 59 - train_loss : 0.0056 - train_acc: 1.0000 - val_loss : 8.5496 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 60 - train_loss : 0.0074 - train_acc: 1.0000 - val_loss : 9.6365 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 61 - train_loss : 0.0070 - train_acc: 1.0000 - val_loss : 9.5115 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 62 - train_loss : 0.0082 - train_acc: 0.9990 - val_loss : 8.4024 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 63 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 8.7159 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 64 - train_loss : 0.0060 - train_acc: 1.0000 - val_loss : 8.9303 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 65 - train_loss : 0.0043 - train_acc: 1.0000 - val_loss : 9.4225 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 66 - train_loss : 0.0044 - train_acc: 1.0000 - val_loss : 9.2716 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 67 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 9.2801 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 68 - train_loss : 0.0044 - train_acc: 1.0000 - val_loss : 9.3515 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 69 - train_loss : 0.0039 - train_acc: 1.0000 - val_loss : 9.5820 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 70 - train_loss : 0.0033 - train_acc: 1.0000 - val_loss : 9.1010 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 71 - train_loss : 0.0035 - train_acc: 1.0000 - val_loss : 9.1296 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 72 - train_loss : 0.0044 - train_acc: 1.0000 - val_loss : 9.2006 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 73 - train_loss : 0.0032 - train_acc: 1.0000 - val_loss : 9.0562 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 74 - train_loss : 0.0030 - train_acc: 1.0000 - val_loss : 9.4150 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 75 - train_loss : 0.0028 - train_acc: 1.0000 - val_loss : 9.0427 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 76 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 9.0157 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 77 - train_loss : 0.0035 - train_acc: 1.0000 - val_loss : 9.0443 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 78 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 9.2439 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 79 - train_loss : 0.0026 - train_acc: 1.0000 - val_loss : 9.6693 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 80 - train_loss : 0.0037 - train_acc: 1.0000 - val_loss : 9.2933 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 81 - train_loss : 0.0028 - train_acc: 1.0000 - val_loss : 9.4934 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 82 - train_loss : 0.0033 - train_acc: 1.0000 - val_loss : 8.9382 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 83 - train_loss : 0.0029 - train_acc: 1.0000 - val_loss : 9.2857 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 84 - train_loss : 0.0032 - train_acc: 1.0000 - val_loss : 9.7307 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 85 - train_loss : 0.0026 - train_acc: 1.0000 - val_loss : 9.7244 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 86 - train_loss : 0.0038 - train_acc: 1.0000 - val_loss : 9.7165 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 87 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 9.5293 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 88 - train_loss : 0.0026 - train_acc: 1.0000 - val_loss : 9.4413 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 89 - train_loss : 0.0024 - train_acc: 1.0000 - val_loss : 9.6620 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 90 - train_loss : 0.0020 - train_acc: 1.0000 - val_loss : 9.3362 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 91 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 9.8323 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 92 - train_loss : 0.0017 - train_acc: 1.0000 - val_loss : 9.9162 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 93 - train_loss : 0.0031 - train_acc: 1.0000 - val_loss : 9.8418 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 94 - train_loss : 0.0020 - train_acc: 1.0000 - val_loss : 9.8139 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 95 - train_loss : 0.0020 - train_acc: 1.0000 - val_loss : 9.9016 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 96 - train_loss : 0.0018 - train_acc: 1.0000 - val_loss : 10.1678 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 97 - train_loss : 0.0020 - train_acc: 1.0000 - val_loss : 9.9020 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 98 - train_loss : 0.0022 - train_acc: 1.0000 - val_loss : 9.9632 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 99 - train_loss : 0.0015 - train_acc: 1.0000 - val_loss : 9.6085 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 100 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 9.7395 - val_acc: 0.0000\n",
      "\n",
      "Fold 4 Test Accuracy:  tensor(0., device='cuda:0')\n",
      "Beginning Fold  5\n",
      "test subs:  [9032 9023]\n",
      "valid subs:  [9047 9044]\n",
      "train case split:  606 : 404\n",
      "valid case split:  101 : 101\n",
      "test case split:  0 : 202 \n",
      "\n",
      "Epoch : 1 - train_loss : 0.6161 - train_acc: 0.7154 - val_loss : 1.0932 - val_acc: 0.3036\n",
      "\n",
      "model saved\n",
      "Epoch : 2 - train_loss : 0.5165 - train_acc: 0.7798 - val_loss : 1.5149 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 3 - train_loss : 0.4212 - train_acc: 0.8088 - val_loss : 1.9345 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 4 - train_loss : 0.2932 - train_acc: 0.9268 - val_loss : 1.7539 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 5 - train_loss : 0.2061 - train_acc: 0.9655 - val_loss : 2.0995 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 6 - train_loss : 0.1443 - train_acc: 0.9905 - val_loss : 2.1652 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 7 - train_loss : 0.1262 - train_acc: 0.9971 - val_loss : 2.1940 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 8 - train_loss : 0.0973 - train_acc: 0.9980 - val_loss : 2.4473 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 9 - train_loss : 0.0935 - train_acc: 0.9951 - val_loss : 2.3232 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 10 - train_loss : 0.0766 - train_acc: 0.9971 - val_loss : 2.4657 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 11 - train_loss : 0.0753 - train_acc: 0.9963 - val_loss : 2.5409 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 12 - train_loss : 0.0698 - train_acc: 0.9990 - val_loss : 2.4096 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 13 - train_loss : 0.0674 - train_acc: 0.9944 - val_loss : 2.6064 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 14 - train_loss : 0.0548 - train_acc: 0.9990 - val_loss : 2.4526 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 15 - train_loss : 0.0543 - train_acc: 1.0000 - val_loss : 2.3622 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 16 - train_loss : 0.0470 - train_acc: 1.0000 - val_loss : 2.4700 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 17 - train_loss : 0.0464 - train_acc: 1.0000 - val_loss : 2.5035 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 18 - train_loss : 0.0429 - train_acc: 1.0000 - val_loss : 2.6492 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 19 - train_loss : 0.0395 - train_acc: 1.0000 - val_loss : 2.8904 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 20 - train_loss : 0.0374 - train_acc: 0.9990 - val_loss : 3.2302 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 21 - train_loss : 0.0354 - train_acc: 1.0000 - val_loss : 2.7327 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 22 - train_loss : 0.0315 - train_acc: 1.0000 - val_loss : 3.0121 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 23 - train_loss : 0.0326 - train_acc: 1.0000 - val_loss : 2.6005 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 24 - train_loss : 0.0307 - train_acc: 1.0000 - val_loss : 3.1324 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 25 - train_loss : 0.0292 - train_acc: 1.0000 - val_loss : 3.3524 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 26 - train_loss : 0.0320 - train_acc: 1.0000 - val_loss : 3.2351 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 27 - train_loss : 0.0251 - train_acc: 1.0000 - val_loss : 3.1589 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 28 - train_loss : 0.0243 - train_acc: 1.0000 - val_loss : 3.0327 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 29 - train_loss : 0.0219 - train_acc: 1.0000 - val_loss : 3.2319 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 30 - train_loss : 0.0204 - train_acc: 1.0000 - val_loss : 3.2653 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 31 - train_loss : 0.0201 - train_acc: 1.0000 - val_loss : 3.5359 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 32 - train_loss : 0.0222 - train_acc: 0.9983 - val_loss : 3.5569 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 33 - train_loss : 0.0269 - train_acc: 0.9961 - val_loss : 2.9680 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 34 - train_loss : 0.0217 - train_acc: 1.0000 - val_loss : 3.6654 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 35 - train_loss : 0.0153 - train_acc: 1.0000 - val_loss : 3.4691 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 36 - train_loss : 0.0245 - train_acc: 0.9965 - val_loss : 3.6965 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 37 - train_loss : 0.0172 - train_acc: 1.0000 - val_loss : 3.1655 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 38 - train_loss : 0.0191 - train_acc: 0.9980 - val_loss : 2.7230 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 39 - train_loss : 0.0151 - train_acc: 1.0000 - val_loss : 3.8295 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 40 - train_loss : 0.0135 - train_acc: 1.0000 - val_loss : 3.8713 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 41 - train_loss : 0.0164 - train_acc: 1.0000 - val_loss : 3.3090 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 42 - train_loss : 0.0113 - train_acc: 1.0000 - val_loss : 3.9568 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 43 - train_loss : 0.0108 - train_acc: 1.0000 - val_loss : 3.6893 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 44 - train_loss : 0.0095 - train_acc: 1.0000 - val_loss : 3.5834 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 45 - train_loss : 0.0120 - train_acc: 1.0000 - val_loss : 3.2319 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 46 - train_loss : 0.0122 - train_acc: 1.0000 - val_loss : 3.6574 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 47 - train_loss : 0.0110 - train_acc: 1.0000 - val_loss : 3.7842 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 48 - train_loss : 0.0095 - train_acc: 1.0000 - val_loss : 3.6023 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 49 - train_loss : 0.0087 - train_acc: 1.0000 - val_loss : 3.9632 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 50 - train_loss : 0.0093 - train_acc: 1.0000 - val_loss : 4.0020 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 51 - train_loss : 0.0081 - train_acc: 1.0000 - val_loss : 3.6232 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 52 - train_loss : 0.0077 - train_acc: 1.0000 - val_loss : 3.6635 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 53 - train_loss : 0.0093 - train_acc: 1.0000 - val_loss : 4.1098 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 54 - train_loss : 0.0075 - train_acc: 1.0000 - val_loss : 4.1144 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 55 - train_loss : 0.0064 - train_acc: 1.0000 - val_loss : 4.2346 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 56 - train_loss : 0.0060 - train_acc: 1.0000 - val_loss : 3.9268 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 57 - train_loss : 0.0064 - train_acc: 1.0000 - val_loss : 4.1965 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 58 - train_loss : 0.0058 - train_acc: 1.0000 - val_loss : 4.2374 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 59 - train_loss : 0.0062 - train_acc: 1.0000 - val_loss : 4.5142 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 60 - train_loss : 0.0093 - train_acc: 1.0000 - val_loss : 3.6455 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 61 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 4.0108 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 62 - train_loss : 0.0074 - train_acc: 1.0000 - val_loss : 4.1359 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 63 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 4.2484 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 64 - train_loss : 0.0061 - train_acc: 1.0000 - val_loss : 4.3227 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 65 - train_loss : 0.0056 - train_acc: 1.0000 - val_loss : 4.6071 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 66 - train_loss : 0.0064 - train_acc: 1.0000 - val_loss : 4.4796 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 67 - train_loss : 0.0051 - train_acc: 1.0000 - val_loss : 4.1006 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 68 - train_loss : 0.0062 - train_acc: 1.0000 - val_loss : 4.2010 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 69 - train_loss : 0.0047 - train_acc: 1.0000 - val_loss : 4.5013 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 70 - train_loss : 0.0055 - train_acc: 1.0000 - val_loss : 4.4633 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 71 - train_loss : 0.0047 - train_acc: 1.0000 - val_loss : 4.7622 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 72 - train_loss : 0.0041 - train_acc: 1.0000 - val_loss : 4.3981 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 73 - train_loss : 0.0034 - train_acc: 1.0000 - val_loss : 4.5865 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 74 - train_loss : 0.0034 - train_acc: 1.0000 - val_loss : 4.4552 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 75 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 4.4290 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 76 - train_loss : 0.0036 - train_acc: 1.0000 - val_loss : 4.8874 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 77 - train_loss : 0.0032 - train_acc: 1.0000 - val_loss : 4.2950 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 78 - train_loss : 0.0033 - train_acc: 1.0000 - val_loss : 4.6707 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 79 - train_loss : 0.0039 - train_acc: 1.0000 - val_loss : 4.5335 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 80 - train_loss : 0.0030 - train_acc: 1.0000 - val_loss : 4.4613 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 81 - train_loss : 0.0040 - train_acc: 1.0000 - val_loss : 4.7940 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 82 - train_loss : 0.0031 - train_acc: 1.0000 - val_loss : 4.7725 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 83 - train_loss : 0.0029 - train_acc: 1.0000 - val_loss : 4.6654 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 84 - train_loss : 0.0057 - train_acc: 1.0000 - val_loss : 4.3107 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 85 - train_loss : 0.0042 - train_acc: 1.0000 - val_loss : 4.9099 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 86 - train_loss : 0.0034 - train_acc: 1.0000 - val_loss : 4.5074 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 87 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 4.7055 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 88 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 4.5760 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 89 - train_loss : 0.0024 - train_acc: 1.0000 - val_loss : 5.1214 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 90 - train_loss : 0.0030 - train_acc: 1.0000 - val_loss : 4.5927 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 91 - train_loss : 0.0021 - train_acc: 1.0000 - val_loss : 5.0791 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 92 - train_loss : 0.0021 - train_acc: 1.0000 - val_loss : 4.1148 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 93 - train_loss : 0.0039 - train_acc: 0.9983 - val_loss : 5.0529 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 94 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 5.2547 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 95 - train_loss : 0.0040 - train_acc: 1.0000 - val_loss : 5.8425 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 96 - train_loss : 0.0031 - train_acc: 1.0000 - val_loss : 4.9975 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 97 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 5.0529 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 98 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 4.8757 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 99 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 4.5613 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 100 - train_loss : 0.0019 - train_acc: 1.0000 - val_loss : 5.1427 - val_acc: 0.0000\n",
      "\n",
      "Fold 5 Test Accuracy:  tensor(0.3482, device='cuda:0')\n",
      "Beginning Fold  6\n",
      "test subs:  [9047 9021]\n",
      "valid subs:  [9032 9044]\n",
      "train case split:  606 : 404\n",
      "valid case split:  101 : 101\n",
      "test case split:  0 : 202 \n",
      "\n",
      "Epoch : 1 - train_loss : 0.6524 - train_acc: 0.5778 - val_loss : 0.8719 - val_acc: 0.1384\n",
      "\n",
      "model saved\n",
      "Epoch : 2 - train_loss : 0.4784 - train_acc: 0.7679 - val_loss : 0.9874 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 3 - train_loss : 0.3670 - train_acc: 0.8557 - val_loss : 1.1648 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 4 - train_loss : 0.2799 - train_acc: 0.9333 - val_loss : 1.5342 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 5 - train_loss : 0.2016 - train_acc: 0.9785 - val_loss : 1.8791 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 6 - train_loss : 0.1387 - train_acc: 0.9980 - val_loss : 2.1588 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 7 - train_loss : 0.1246 - train_acc: 0.9980 - val_loss : 2.5245 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 8 - train_loss : 0.0935 - train_acc: 1.0000 - val_loss : 2.7666 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 9 - train_loss : 0.0835 - train_acc: 0.9980 - val_loss : 2.8853 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 10 - train_loss : 0.0771 - train_acc: 1.0000 - val_loss : 3.1501 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 11 - train_loss : 0.0634 - train_acc: 1.0000 - val_loss : 3.1831 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 12 - train_loss : 0.0639 - train_acc: 1.0000 - val_loss : 3.2062 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 13 - train_loss : 0.0595 - train_acc: 0.9941 - val_loss : 3.2173 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 14 - train_loss : 0.0548 - train_acc: 0.9990 - val_loss : 3.2749 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 15 - train_loss : 0.0454 - train_acc: 1.0000 - val_loss : 3.5378 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 16 - train_loss : 0.0433 - train_acc: 1.0000 - val_loss : 3.6147 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 17 - train_loss : 0.0458 - train_acc: 1.0000 - val_loss : 3.8370 - val_acc: 0.0536\n",
      "\n",
      "Epoch : 18 - train_loss : 0.0441 - train_acc: 0.9931 - val_loss : 3.6984 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 19 - train_loss : 0.0336 - train_acc: 1.0000 - val_loss : 3.7822 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 20 - train_loss : 0.0339 - train_acc: 0.9990 - val_loss : 3.6624 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 21 - train_loss : 0.0292 - train_acc: 1.0000 - val_loss : 3.8250 - val_acc: 0.0089\n",
      "\n",
      "Epoch : 22 - train_loss : 0.0342 - train_acc: 1.0000 - val_loss : 4.0796 - val_acc: 0.0045\n",
      "\n",
      "Epoch : 23 - train_loss : 0.0432 - train_acc: 0.9941 - val_loss : 3.9517 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 24 - train_loss : 0.0283 - train_acc: 1.0000 - val_loss : 4.2799 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 25 - train_loss : 0.0225 - train_acc: 1.0000 - val_loss : 4.1280 - val_acc: 0.0357\n",
      "\n",
      "Epoch : 26 - train_loss : 0.0227 - train_acc: 1.0000 - val_loss : 4.1471 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 27 - train_loss : 0.0215 - train_acc: 1.0000 - val_loss : 4.2430 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 28 - train_loss : 0.0220 - train_acc: 1.0000 - val_loss : 4.3988 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 29 - train_loss : 0.0237 - train_acc: 1.0000 - val_loss : 4.5436 - val_acc: 0.0089\n",
      "\n",
      "Epoch : 30 - train_loss : 0.0189 - train_acc: 1.0000 - val_loss : 4.3158 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 31 - train_loss : 0.0150 - train_acc: 1.0000 - val_loss : 4.3667 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 32 - train_loss : 0.0166 - train_acc: 1.0000 - val_loss : 4.5485 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 33 - train_loss : 0.0198 - train_acc: 1.0000 - val_loss : 4.4396 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 34 - train_loss : 0.0150 - train_acc: 1.0000 - val_loss : 4.6254 - val_acc: 0.0045\n",
      "\n",
      "Epoch : 35 - train_loss : 0.0159 - train_acc: 0.9980 - val_loss : 4.4392 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 36 - train_loss : 0.0173 - train_acc: 0.9990 - val_loss : 4.7316 - val_acc: 0.0714\n",
      "\n",
      "Epoch : 37 - train_loss : 0.0164 - train_acc: 1.0000 - val_loss : 5.0218 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 38 - train_loss : 0.0123 - train_acc: 1.0000 - val_loss : 4.6989 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 39 - train_loss : 0.0117 - train_acc: 1.0000 - val_loss : 4.8312 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 40 - train_loss : 0.0151 - train_acc: 1.0000 - val_loss : 4.8574 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 41 - train_loss : 0.0116 - train_acc: 1.0000 - val_loss : 4.9071 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 42 - train_loss : 0.0104 - train_acc: 1.0000 - val_loss : 4.9010 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 43 - train_loss : 0.0096 - train_acc: 1.0000 - val_loss : 5.0495 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 44 - train_loss : 0.0099 - train_acc: 1.0000 - val_loss : 5.0166 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 45 - train_loss : 0.0097 - train_acc: 1.0000 - val_loss : 4.9198 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 46 - train_loss : 0.0085 - train_acc: 1.0000 - val_loss : 5.1666 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 47 - train_loss : 0.0086 - train_acc: 1.0000 - val_loss : 4.9719 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 48 - train_loss : 0.0084 - train_acc: 1.0000 - val_loss : 5.2440 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 49 - train_loss : 0.0074 - train_acc: 1.0000 - val_loss : 5.1124 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 50 - train_loss : 0.0076 - train_acc: 1.0000 - val_loss : 5.2520 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 51 - train_loss : 0.0075 - train_acc: 1.0000 - val_loss : 5.4625 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 52 - train_loss : 0.0081 - train_acc: 1.0000 - val_loss : 5.1402 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 53 - train_loss : 0.0077 - train_acc: 1.0000 - val_loss : 5.2192 - val_acc: 0.0580\n",
      "\n",
      "Epoch : 54 - train_loss : 0.0088 - train_acc: 1.0000 - val_loss : 5.3924 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 55 - train_loss : 0.0062 - train_acc: 1.0000 - val_loss : 5.2784 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 56 - train_loss : 0.0053 - train_acc: 1.0000 - val_loss : 5.1586 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 57 - train_loss : 0.0076 - train_acc: 1.0000 - val_loss : 5.3607 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 58 - train_loss : 0.0095 - train_acc: 1.0000 - val_loss : 6.0271 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 59 - train_loss : 0.0080 - train_acc: 1.0000 - val_loss : 5.1384 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 60 - train_loss : 0.0145 - train_acc: 0.9980 - val_loss : 5.3615 - val_acc: 0.0670\n",
      "\n",
      "Epoch : 61 - train_loss : 0.0056 - train_acc: 1.0000 - val_loss : 5.4837 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 62 - train_loss : 0.0056 - train_acc: 1.0000 - val_loss : 5.6482 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 63 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 5.9420 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 64 - train_loss : 0.0047 - train_acc: 1.0000 - val_loss : 5.4901 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 65 - train_loss : 0.0063 - train_acc: 1.0000 - val_loss : 5.3652 - val_acc: 0.0223\n",
      "\n",
      "Epoch : 66 - train_loss : 0.0133 - train_acc: 0.9961 - val_loss : 5.4908 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 67 - train_loss : 0.0066 - train_acc: 1.0000 - val_loss : 5.9530 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 68 - train_loss : 0.0049 - train_acc: 1.0000 - val_loss : 5.4553 - val_acc: 0.0134\n",
      "\n",
      "Epoch : 69 - train_loss : 0.0048 - train_acc: 1.0000 - val_loss : 5.3569 - val_acc: 0.0357\n",
      "\n",
      "Epoch : 70 - train_loss : 0.0049 - train_acc: 1.0000 - val_loss : 5.6138 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 71 - train_loss : 0.0098 - train_acc: 0.9990 - val_loss : 6.0270 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 72 - train_loss : 0.0065 - train_acc: 1.0000 - val_loss : 6.4703 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 73 - train_loss : 0.0043 - train_acc: 1.0000 - val_loss : 5.8050 - val_acc: 0.0045\n",
      "\n",
      "Epoch : 74 - train_loss : 0.0045 - train_acc: 1.0000 - val_loss : 5.5748 - val_acc: 0.0045\n",
      "\n",
      "Epoch : 75 - train_loss : 0.0046 - train_acc: 1.0000 - val_loss : 5.8564 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 76 - train_loss : 0.0060 - train_acc: 1.0000 - val_loss : 6.1587 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 77 - train_loss : 0.0051 - train_acc: 1.0000 - val_loss : 5.9699 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 78 - train_loss : 0.0057 - train_acc: 0.9983 - val_loss : 6.5552 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 79 - train_loss : 0.0041 - train_acc: 1.0000 - val_loss : 5.5445 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 80 - train_loss : 0.0037 - train_acc: 1.0000 - val_loss : 5.6734 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 81 - train_loss : 0.0032 - train_acc: 1.0000 - val_loss : 5.6905 - val_acc: 0.0089\n",
      "\n",
      "Epoch : 82 - train_loss : 0.0038 - train_acc: 1.0000 - val_loss : 5.6870 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 83 - train_loss : 0.0071 - train_acc: 0.9971 - val_loss : 5.9958 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 84 - train_loss : 0.0028 - train_acc: 1.0000 - val_loss : 5.9623 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 85 - train_loss : 0.0031 - train_acc: 1.0000 - val_loss : 5.8631 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 86 - train_loss : 0.0030 - train_acc: 1.0000 - val_loss : 5.9465 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 87 - train_loss : 0.0040 - train_acc: 1.0000 - val_loss : 6.2266 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 88 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 6.3630 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 89 - train_loss : 0.0031 - train_acc: 1.0000 - val_loss : 6.3244 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 90 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 6.1636 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 91 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 5.9635 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 92 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 6.3467 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 93 - train_loss : 0.0022 - train_acc: 1.0000 - val_loss : 6.2690 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 94 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 6.1211 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 95 - train_loss : 0.0026 - train_acc: 1.0000 - val_loss : 6.1416 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 96 - train_loss : 0.0020 - train_acc: 1.0000 - val_loss : 6.0745 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 97 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 5.9033 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 98 - train_loss : 0.0023 - train_acc: 1.0000 - val_loss : 6.0850 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 99 - train_loss : 0.0141 - train_acc: 0.9902 - val_loss : 6.8198 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 100 - train_loss : 0.0029 - train_acc: 1.0000 - val_loss : 6.4438 - val_acc: 0.0089\n",
      "\n",
      "Fold 6 Test Accuracy:  tensor(0., device='cuda:0')\n",
      "Beginning Fold  7\n",
      "test subs:  [9051 9044]\n",
      "valid subs:  [9032 9045]\n",
      "train case split:  505 : 505\n",
      "valid case split:  101 : 101\n",
      "test case split:  101 : 101 \n",
      "\n",
      "Epoch : 1 - train_loss : 0.6694 - train_acc: 0.6138 - val_loss : 0.7406 - val_acc: 0.5491\n",
      "\n",
      "model saved\n",
      "Epoch : 2 - train_loss : 0.5849 - train_acc: 0.7687 - val_loss : 0.9108 - val_acc: 0.5348\n",
      "\n",
      "Epoch : 3 - train_loss : 0.4700 - train_acc: 0.8479 - val_loss : 1.2978 - val_acc: 0.5491\n",
      "\n",
      "Epoch : 4 - train_loss : 0.3281 - train_acc: 0.9184 - val_loss : 1.7312 - val_acc: 0.0473\n",
      "\n",
      "Epoch : 5 - train_loss : 0.2174 - train_acc: 0.9775 - val_loss : 2.5505 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 6 - train_loss : 0.1645 - train_acc: 0.9856 - val_loss : 3.0435 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 7 - train_loss : 0.1311 - train_acc: 0.9932 - val_loss : 2.6844 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 8 - train_loss : 0.1099 - train_acc: 0.9951 - val_loss : 3.0610 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 9 - train_loss : 0.1049 - train_acc: 0.9951 - val_loss : 3.6532 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 10 - train_loss : 0.1236 - train_acc: 0.9693 - val_loss : 2.6595 - val_acc: 0.0045\n",
      "\n",
      "Epoch : 11 - train_loss : 0.0824 - train_acc: 0.9990 - val_loss : 3.6547 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 12 - train_loss : 0.0840 - train_acc: 0.9912 - val_loss : 3.7489 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 13 - train_loss : 0.0816 - train_acc: 0.9990 - val_loss : 3.9402 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 14 - train_loss : 0.0752 - train_acc: 0.9963 - val_loss : 3.4081 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 15 - train_loss : 0.0616 - train_acc: 1.0000 - val_loss : 3.9144 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 16 - train_loss : 0.0637 - train_acc: 0.9980 - val_loss : 3.8738 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 17 - train_loss : 0.0648 - train_acc: 0.9990 - val_loss : 4.1652 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 18 - train_loss : 0.0588 - train_acc: 0.9971 - val_loss : 4.1066 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 19 - train_loss : 0.0522 - train_acc: 1.0000 - val_loss : 4.1196 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 20 - train_loss : 0.0473 - train_acc: 1.0000 - val_loss : 3.9016 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 21 - train_loss : 0.0487 - train_acc: 0.9971 - val_loss : 4.1260 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 22 - train_loss : 0.0440 - train_acc: 1.0000 - val_loss : 4.0600 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 23 - train_loss : 0.0422 - train_acc: 0.9971 - val_loss : 4.1946 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 24 - train_loss : 0.0394 - train_acc: 1.0000 - val_loss : 3.4227 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 25 - train_loss : 0.0480 - train_acc: 0.9944 - val_loss : 4.9802 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 26 - train_loss : 0.0382 - train_acc: 1.0000 - val_loss : 3.7671 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 27 - train_loss : 0.0366 - train_acc: 1.0000 - val_loss : 4.3334 - val_acc: 0.0045\n",
      "\n",
      "Epoch : 28 - train_loss : 0.0397 - train_acc: 0.9963 - val_loss : 3.4653 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 29 - train_loss : 0.0324 - train_acc: 1.0000 - val_loss : 4.9711 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 30 - train_loss : 0.0254 - train_acc: 1.0000 - val_loss : 4.1034 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 31 - train_loss : 0.0275 - train_acc: 1.0000 - val_loss : 4.1869 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 32 - train_loss : 0.0266 - train_acc: 0.9990 - val_loss : 4.4917 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 33 - train_loss : 0.0225 - train_acc: 1.0000 - val_loss : 4.7564 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 34 - train_loss : 0.0207 - train_acc: 1.0000 - val_loss : 4.6424 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 35 - train_loss : 0.0240 - train_acc: 1.0000 - val_loss : 4.9792 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 36 - train_loss : 0.0195 - train_acc: 1.0000 - val_loss : 4.3986 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 37 - train_loss : 0.0197 - train_acc: 1.0000 - val_loss : 4.9671 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 38 - train_loss : 0.0197 - train_acc: 1.0000 - val_loss : 4.7518 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 39 - train_loss : 0.0151 - train_acc: 1.0000 - val_loss : 4.9219 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 40 - train_loss : 0.0154 - train_acc: 1.0000 - val_loss : 4.7093 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 41 - train_loss : 0.0168 - train_acc: 1.0000 - val_loss : 5.5170 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 42 - train_loss : 0.0147 - train_acc: 1.0000 - val_loss : 4.7415 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 43 - train_loss : 0.0157 - train_acc: 1.0000 - val_loss : 5.3368 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 44 - train_loss : 0.0172 - train_acc: 1.0000 - val_loss : 5.1293 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 45 - train_loss : 0.0255 - train_acc: 0.9932 - val_loss : 4.1721 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 46 - train_loss : 0.0214 - train_acc: 0.9980 - val_loss : 4.4522 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 47 - train_loss : 0.0135 - train_acc: 1.0000 - val_loss : 5.0070 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 48 - train_loss : 0.0110 - train_acc: 1.0000 - val_loss : 4.7368 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 49 - train_loss : 0.0140 - train_acc: 1.0000 - val_loss : 4.9217 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 50 - train_loss : 0.0102 - train_acc: 1.0000 - val_loss : 4.8416 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 51 - train_loss : 0.0120 - train_acc: 1.0000 - val_loss : 5.0020 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 52 - train_loss : 0.0122 - train_acc: 1.0000 - val_loss : 5.0847 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 53 - train_loss : 0.0112 - train_acc: 1.0000 - val_loss : 5.5717 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 54 - train_loss : 0.0087 - train_acc: 1.0000 - val_loss : 4.9571 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 55 - train_loss : 0.0072 - train_acc: 1.0000 - val_loss : 4.9205 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 56 - train_loss : 0.0092 - train_acc: 1.0000 - val_loss : 4.6589 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 57 - train_loss : 0.0073 - train_acc: 1.0000 - val_loss : 5.0383 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 58 - train_loss : 0.0083 - train_acc: 1.0000 - val_loss : 6.0680 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 59 - train_loss : 0.0082 - train_acc: 1.0000 - val_loss : 5.6825 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 60 - train_loss : 0.0169 - train_acc: 0.9951 - val_loss : 6.4041 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 61 - train_loss : 0.0084 - train_acc: 1.0000 - val_loss : 4.5317 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 62 - train_loss : 0.0059 - train_acc: 1.0000 - val_loss : 5.0250 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 63 - train_loss : 0.0083 - train_acc: 1.0000 - val_loss : 4.7910 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 64 - train_loss : 0.0067 - train_acc: 1.0000 - val_loss : 4.5460 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 65 - train_loss : 0.0058 - train_acc: 1.0000 - val_loss : 4.9612 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 66 - train_loss : 0.0091 - train_acc: 1.0000 - val_loss : 4.7075 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 67 - train_loss : 0.0071 - train_acc: 1.0000 - val_loss : 5.5395 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 68 - train_loss : 0.0066 - train_acc: 1.0000 - val_loss : 5.4271 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 69 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 5.3569 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 70 - train_loss : 0.0067 - train_acc: 1.0000 - val_loss : 5.2195 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 71 - train_loss : 0.0065 - train_acc: 1.0000 - val_loss : 4.8981 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 72 - train_loss : 0.0068 - train_acc: 1.0000 - val_loss : 4.4377 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 73 - train_loss : 0.0072 - train_acc: 0.9990 - val_loss : 5.3341 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 74 - train_loss : 0.0078 - train_acc: 1.0000 - val_loss : 5.7942 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 75 - train_loss : 0.0107 - train_acc: 0.9973 - val_loss : 4.4784 - val_acc: 0.0134\n",
      "\n",
      "Epoch : 76 - train_loss : 0.0074 - train_acc: 1.0000 - val_loss : 5.4561 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 77 - train_loss : 0.0050 - train_acc: 1.0000 - val_loss : 5.1637 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 78 - train_loss : 0.0062 - train_acc: 1.0000 - val_loss : 5.5675 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 79 - train_loss : 0.0046 - train_acc: 1.0000 - val_loss : 5.0524 - val_acc: 0.0045\n",
      "\n",
      "Epoch : 80 - train_loss : 0.0045 - train_acc: 1.0000 - val_loss : 5.0823 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 81 - train_loss : 0.0031 - train_acc: 1.0000 - val_loss : 5.0313 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 82 - train_loss : 0.0052 - train_acc: 1.0000 - val_loss : 5.0897 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 83 - train_loss : 0.0042 - train_acc: 1.0000 - val_loss : 5.3850 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 84 - train_loss : 0.0031 - train_acc: 1.0000 - val_loss : 5.2939 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 85 - train_loss : 0.0029 - train_acc: 1.0000 - val_loss : 4.7987 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 86 - train_loss : 0.0037 - train_acc: 1.0000 - val_loss : 5.4339 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 87 - train_loss : 0.0053 - train_acc: 1.0000 - val_loss : 5.3336 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 88 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 5.2092 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 89 - train_loss : 0.0034 - train_acc: 1.0000 - val_loss : 4.3823 - val_acc: 0.0134\n",
      "\n",
      "Epoch : 90 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 5.0545 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 91 - train_loss : 0.0022 - train_acc: 1.0000 - val_loss : 5.3058 - val_acc: 0.0045\n",
      "\n",
      "Epoch : 92 - train_loss : 0.0027 - train_acc: 1.0000 - val_loss : 5.4018 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 93 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 4.7114 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 94 - train_loss : 0.0021 - train_acc: 1.0000 - val_loss : 5.3015 - val_acc: 0.0134\n",
      "\n",
      "Epoch : 95 - train_loss : 0.0020 - train_acc: 1.0000 - val_loss : 5.5324 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 96 - train_loss : 0.0024 - train_acc: 1.0000 - val_loss : 5.4982 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 97 - train_loss : 0.0028 - train_acc: 1.0000 - val_loss : 4.9325 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 98 - train_loss : 0.0022 - train_acc: 1.0000 - val_loss : 5.4847 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 99 - train_loss : 0.0039 - train_acc: 1.0000 - val_loss : 6.0059 - val_acc: 0.0000\n",
      "\n",
      "Epoch : 100 - train_loss : 0.0025 - train_acc: 1.0000 - val_loss : 4.7280 - val_acc: 0.0000\n",
      "\n",
      "Fold 7 Test Accuracy:  tensor(0.4589, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.45893</td></tr><tr><td>train_acc</td><td>1.0</td></tr><tr><td>train_loss</td><td>0.0013</td></tr><tr><td>val_acc</td><td>0.0</td></tr><tr><td>val_loss</td><td>1.43533</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">apricot-violet-30</strong>: <a href=\"https://wandb.ai/aalbizu/SMART-CNN-2D_II/runs/8k1qzznx\" target=\"_blank\">https://wandb.ai/aalbizu/SMART-CNN-2D_II/runs/8k1qzznx</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220706_000657-8k1qzznx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 202, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b4b66e0939dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m print(classification_report(\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0malltargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mallpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1985\u001b[0m             )\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1987\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1988\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 202, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Set data directory\n",
    "rootDir = '/blue/camctrp/working/Alejandro/StimBrain/'\n",
    "dims = np.array([182,218,182])\n",
    "batch_size=32\n",
    "im_size = (128,128)\n",
    "seed = 42\n",
    "subs = np.array([9009, 9015, 9022, 9040, 9044, 9045, 9051, 9021, 9023, 9031, 9032, 9047, 9048, 9054]) # Subjects\n",
    "beh = np.array([32, 26, 19, 20, 20, 17, 15, 2, 4, 6, 10, 16, 18, 7]) # Targeted Behavior Change\n",
    "lr = 1e-5\n",
    "wd = 0\n",
    "K = 7 # MUST BE A FACTOR OF NUM SUBS\n",
    "datatype = \"Jxyz2D\"\n",
    "pat_size = (25,25)\n",
    "pretrain = False;\n",
    "\n",
    "# start a typical PyTorch training\n",
    "val_interval = 1\n",
    "epoch_loss_values = [] # Pre-Allocate\n",
    "epoch_acc_values = [] # Pre-Allocate\n",
    "max_epochs = 100\n",
    "num_cores = int(os.environ[\"SLURM_CPUS_PER_TASK\"]);\n",
    "\n",
    "# Define Group Labels as above/below Median\n",
    "l = np.int64(np.zeros([len(beh),1]));\n",
    "l[beh >= np.median(beh)] = 1; # Responders\n",
    "l[beh < np.median(beh)] = 0; # Non Responders\n",
    "\n",
    "\n",
    "# INITIATE WEIGHTS AND BIASES\n",
    "wb.init(project=\"SMART-CNN-2D_II\",\n",
    "        config={\n",
    "            \"batch_size\": batch_size,\n",
    "            \"n_channels\": 3,\n",
    "            \"n_epoch\": max_epochs,\n",
    "            \"folds\": K,\n",
    "            \"image_size\": im_size,\n",
    "            \"pre-trained\": pretrain,\n",
    "              \"patch_size\": pat_size,\n",
    "            \"learning_rate\": lr,\n",
    "            \"network\": \"ResNet10\",\n",
    "            \"weight_decay\": wd,\n",
    "            \"dataset\": \"SB\",\n",
    "        })\n",
    "run_id = wb.run.name;\n",
    "\n",
    "class Diagnosis(Enum):\n",
    "    NonResponder = 0\n",
    "    Responder = 1\n",
    "    \n",
    "def save_model(n_epoch, save_path, run_id):\n",
    "    lastmodel = f\"{save_path}-{run_id}-fold{f}.pth\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"best_valid_score\": best_valid_score,\n",
    "            \"n_epoch\": n_epoch,\n",
    "        },\n",
    "        lastmodel,\n",
    "    )\n",
    "\n",
    "# Define Train/Validation/Test Set # WIP PERFORM 5 FOLD CROSS VALIDATION\n",
    "\n",
    "# nontest_subs, test_subs, y_nontest, y_test = train_test_split(subs, l, test_size=0.10, stratify=l, random_state=seed);\n",
    "butt = [0,1];\n",
    "testIdx = np.array(random.sample(list(np.arange(subs.shape[0])),subs.shape[0]));\n",
    "alltargs = []; allpreds = []; allscores = []; # Pre-Allocate\n",
    "for f in range(K):\n",
    "    print(\"Beginning Fold \", f+1)\n",
    "    test_subs = subs[testIdx[butt]]; print('test subs: ', test_subs)\n",
    "    nontest_subs = subs[np.logical_not(np.isin(subs,test_subs))]\n",
    "    y_nontest = l[np.logical_not(np.isin(subs,test_subs))]\n",
    "    train_subs, valid_subs, y_train, y_valid = train_test_split(nontest_subs, y_nontest, test_size=0.10, stratify=y_nontest, random_state=seed); print('valid subs: ',valid_subs) \n",
    "\n",
    "    test_list = []; valid_list = []; train_list = [];\n",
    "    test_label = []; valid_label = []; train_label = [];\n",
    "    for s in range(subs.shape[0]):\n",
    "        for n in range(dims[2]):\n",
    "                if n < 50 or n > 150: continue\n",
    "                if np.isin(test_subs,subs[s]).any():\n",
    "                    test_list.append(os.path.join(rootDir,'FS6.0_sub-'+str(subs[s])+'_ses01','sub-'+str(subs[s])+'_n'+str(n+1)+'_Jxyz.png'));\n",
    "                    test_label.append(l[s]);\n",
    "                elif np.isin(train_subs,subs[s]).any():\n",
    "                    train_list.append(os.path.join(rootDir,'FS6.0_sub-'+str(subs[s])+'_ses01','sub-'+str(subs[s])+'_n'+str(n+1)+'_Jxyz.png'));\n",
    "                    train_label.append(l[s]);\n",
    "                elif np.isin(valid_subs,subs[s]).any():\n",
    "                    valid_list.append(os.path.join(rootDir,'FS6.0_sub-'+str(subs[s])+'_ses01','sub-'+str(subs[s])+'_n'+str(n+1)+'_Jxyz.png'));\n",
    "                    valid_label.append(l[s]);\n",
    "\n",
    "    train_list = np.array(train_list); train_label = np.array(train_label);                  \n",
    "    valid_list = np.array(valid_list); valid_label = np.array(valid_label);                  \n",
    "    test_list = np.array(test_list); test_label = np.array(test_label);                  \n",
    "                \n",
    "    # Plot Labels\n",
    "#     plt.rcParams['figure.figsize'] = [20, 20]; plt.imshow(np.asarray([train_list.T])); plt.axis('off'); plt.title('Class Labels');\n",
    "\n",
    "# def seed_everything(seed):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# seed_everything(seed)    \n",
    "\n",
    "# Oversampling the Unbalnaced Class\n",
    "# train_list = np.array(np.hstack([[train_list.T],[train_list.T]]))[0,:];\n",
    "# train_label = np.array([np.int64(np.hstack([train_label[:,0],train_label[:,0]]))]).T;\n",
    "\n",
    "    print('train case split: ',sum(train_label)[0],':',len(train_label)-sum(train_label)[0])\n",
    "    print('valid case split: ',sum(valid_label)[0],':',len(valid_label)-sum(valid_label)[0])\n",
    "    print('test case split: ',sum(test_label)[0],':',len(test_label)-sum(test_label)[0],'\\n')\n",
    "\n",
    "# Plot Responder Mean\n",
    "# plt.rcParams['figure.figsize'] = [5,5];\n",
    "# print(train_list[200])\n",
    "# img = plt.imread(train_list[200]); print(img.shape) # Load Each Electrode\n",
    "# plt.imshow(img, cmap=\"turbo\", vmin=0, vmax=1e-100); plt.axis('off'); # Plot\n",
    "\n",
    "# Represent labels in one-hot format for binary classifier training,\n",
    "# BCEWithLogitsLoss requires target to have same shape as input\n",
    "# labels = nn.functional.one_hot(torch.as_tensor(lab).T).long();\n",
    "    train_lab = nn.functional.one_hot(torch.as_tensor(train_label).T).long(); \n",
    "    valid_lab = nn.functional.one_hot(torch.as_tensor(valid_label).T).long();\n",
    "    test_lab = nn.functional.one_hot(torch.as_tensor(test_label).T).long();\n",
    "\n",
    "    # Define transforms\n",
    "    train_transforms = Compose([\n",
    "        AsChannelFirst(channel_dim=2),\n",
    "    #     AddChannel(),\n",
    "        Resize(im_size),\n",
    "    #     RandBiasField(),\n",
    "        RandGaussianNoise(prob=0.1), \n",
    "    #     ScaleIntensity(minv=0.0, maxv=1.0),\n",
    "        EnsureType(data_type='tensor')]);\n",
    "\n",
    "    val_transforms = Compose([\n",
    "        AsChannelFirst(channel_dim=2),\n",
    "    #     AddChannel(),\n",
    "        Resize(im_size),\n",
    "    #     ScaleIntensity(minv=0.0, maxv=1.0),\n",
    "        EnsureType(data_type='tensor')]);\n",
    "\n",
    "    # Define nifti dataset, data loader\n",
    "    check_ds = ImageDataset(image_files=train_list, labels=train_lab[0,:,:], transform=train_transforms);\n",
    "    check_loader = DataLoader(check_ds, batch_size=1, num_workers=num_cores, pin_memory=pin_memory); \n",
    "\n",
    "    # im, label = monai.utils.misc.first(check_loader); print(im.shape, label, label.shape)\n",
    "    # plt.imshow(im[0,:,:,:].T, cmap=\"turbo\", origin=\"lower\"); plt.axis('off'); del check_ds, check_loader, im, label;\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = ImageDataset(image_files=train_list, labels=train_lab[0,:,:], transform=train_transforms);\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_cores, pin_memory=pin_memory);\n",
    "\n",
    "    # create a validation data loader\n",
    "    val_ds = ImageDataset(image_files=valid_list, labels=valid_lab[0,:,:], transform=val_transforms);\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=num_cores, pin_memory=pin_memory)\n",
    "\n",
    "    # Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "#     model = monai.networks.nets.DenseNet121(spatial_dims=2, in_channels=3, out_channels=2, pretrained=pretrain, progress=False).to(device)\n",
    "    model = monai.networks.nets.resnet10(spatial_dims=2, num_classes=2, pretrained=pretrain, progress=False).to(device)\n",
    "#     model = monai.networks.nets.ViT(in_channels=3, img_size=im_size, patch_size=pat_size, classification=True, num_classes=2, spatial_dims=2).to(device)\n",
    "\n",
    "    # Loss Function\n",
    "    loss_fx = torch.nn.BCEWithLogitsLoss() # DenseNet\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    \n",
    "    wb.watch(model, log='all')\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    best_valid_score = 99999; # Initialize Loss\n",
    "    lastmodel = None\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            inputs, label = batch_data[0].to(device), batch_data[1].to(device);\n",
    "\n",
    "            # Evaluate Model\n",
    "            output = model(inputs);\n",
    "            loss = loss_fx(output, label.float())\n",
    "\n",
    "            # Update Gradient\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # Evaluate Model\n",
    "                output = model(inputs); epoch_prob = torch.nn.functional.softmax(output,dim=1)\n",
    "                loss = loss_fx(output, label.float())\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Accuracy\n",
    "            acc = (epoch_prob.argmax(dim=1) == label.argmax(dim=1)).float().mean()\n",
    "            epoch_accuracy += acc / len(train_loader)\n",
    "            epoch_acc_values.append(acc)\n",
    "\n",
    "            # Loss\n",
    "            epoch_loss += loss / len(train_loader)\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "    #         print(f\"train loss: {loss.item():.4f}\")\n",
    "            wb.log({'train_loss': loss, 'train_acc': acc})\n",
    "\n",
    "        if epoch % val_interval == 0: # Validation Interval\n",
    "            with eval_mode(model):\n",
    "                epoch_val_accuracy = 0; epoch_val_loss = 0;\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "\n",
    "                    val_output = model(val_images); val_prob = torch.nn.functional.softmax(val_output,dim=1);\n",
    "                    val_loss = loss_fx(val_output, val_labels.float())\n",
    "\n",
    "                    val_acc = (val_prob.argmax(dim=1) == val_labels.argmax(dim=1)).float().mean()\n",
    "                    epoch_val_accuracy += val_acc / len(val_loader)\n",
    "                    epoch_val_loss += val_loss / len(val_loader)\n",
    "                    wb.log({'val_loss': val_loss, 'val_acc': val_acc})\n",
    "            print(\n",
    "                f\"Epoch : {epoch+1} - train_loss : {epoch_loss:.4f} - train_acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "            # Save Best Model\n",
    "            if best_valid_score > epoch_val_loss:\n",
    "                print(\"model saved\")\n",
    "                save_model(epoch, datatype, run_id)\n",
    "                best_valid_score = epoch_val_loss\n",
    "\n",
    "        else:    \n",
    "            print(\n",
    "                f\"Epoch : {epoch+1} - train_loss : {epoch_loss:.4f} - train_acc: {epoch_accuracy:.4f} \\n\"\n",
    "            )\n",
    "            \n",
    "    ###############\n",
    "    #  Test Model #\n",
    "    ###############\n",
    "    \n",
    "    modelfile = f'{datatype}-{run_id}-fold{f}.pth'; # HARDCODED\n",
    "    checkpoint = torch.load(modelfile)\n",
    "\n",
    "    # create a validation data loader\n",
    "    test_ds = ImageDataset(image_files=test_list, labels=test_lab[0,:,:], transform=val_transforms)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, num_workers=num_cores, pin_memory=pin_memory)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    with eval_mode(model):\n",
    "        y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "        y_prob = torch.tensor([], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor([], dtype=torch.long, device=device)\n",
    "        test_acc = 0\n",
    "        for test_data in test_loader:\n",
    "            test_images, test_labels = test_data[0].to(\n",
    "                device), test_data[1].to(device)\n",
    "\n",
    "            outputs = model(test_images); probs = torch.nn.functional.softmax(outputs,dim=1);\n",
    "#             test_loss = loss_fx(outputs, test_labels.float())\n",
    "            test_acc += (probs.argmax(dim=1) == test_labels.argmax(dim=1)).float().mean();\n",
    "            y_prob = torch.cat([y_prob, probs], dim=0)\n",
    "            y_pred = torch.cat([y_pred, probs.argmax(dim=1)], dim=0)\n",
    "            y = torch.cat([y, test_labels.argmax(dim=1)], dim=0);\n",
    "        test_acc = test_acc / len(test_loader)\n",
    "        alltargs.append(y.cpu().numpy())\n",
    "        allpreds.append(y_pred.cpu().numpy())\n",
    "        allscores.append(y_prob.cpu().numpy())\n",
    "        print(f\"Fold {f+1} Test Accuracy: \", test_acc.float())\n",
    "#         wb.log({'test_loss': test_loss, 'test_acc': test_acc})\n",
    "        wb.log({'test_acc': test_acc})\n",
    "    butt = [ x + 2 for x in butt ]\n",
    "\n",
    "wb.finish()    \n",
    "\n",
    "print(classification_report(\n",
    "    alltargs,\n",
    "    allpreds,\n",
    "    target_names=[d.name for d in Diagnosis]))\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    alltargs,\n",
    "    allpreds,\n",
    "    normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=[d.name for d in Diagnosis])\n",
    "    \n",
    "print(\"Test Accuracy: \", np.mean(alltargs == np.sign(allscores)).float())\n",
    "\n",
    "disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1])\n",
    "    # wb.run.log_code(root=os.path.join(os.getcwd(),\"CNN_SMART.ipynb\")); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af5665-e36f-4a28-8a57-722c31a90ae9",
   "metadata": {},
   "source": [
    "# Occulusion Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c1e16-bda4-44b8-86a6-bd3b12459ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam = monai.visualize.CAM(nn_module=model_3d, target_layers=\"class_layers.relu\", fc_layers=\"class_layers.out\")\n",
    "cam = monai.visualize.GradCAMpp(\n",
    "    nn_module=model, target_layers=\"class_layers.relu\"\n",
    ")\n",
    "# cam = monai.visualize.GradCAMpp(nn_module=model_3d, target_layers=\"class_layers.relu\")\n",
    "print(\n",
    "    \"original feature shape\",\n",
    "    cam.feature_map_size([1, 3] + list(im_size), device),\n",
    ")\n",
    "print(\"upsampled feature shape\", [1, 3] + list(im_size))\n",
    "\n",
    "occ_sens = monai.visualize.OcclusionSensitivity(\n",
    "    nn_module=model, mask_size=4, n_batch=1, stride=4\n",
    ")\n",
    "\n",
    "# For occlusion sensitivity, inference must be run many times. Hence, we can use a\n",
    "# bounding box to limit it to a 2D plane of interest (z=the_slice) where each of\n",
    "# the arguments are the min and max for each of the dimensions (in this case CHWD).\n",
    "\n",
    "train_transforms.set_random_state(42)\n",
    "n_examples = 3\n",
    "subplot_shape = [3, n_examples]\n",
    "fig, axes = plt.subplots(*subplot_shape, figsize=(25, 15), facecolor=\"white\")\n",
    "items = np.random.choice(len(train_ds), size=len(train_ds), replace=False)\n",
    "\n",
    "example = 0\n",
    "for item in items:\n",
    "\n",
    "    data = train_ds[\n",
    "        item\n",
    "    ]  # this fetches training data with random augmentations\n",
    "    image, label = data[0].to(device).unsqueeze(0), data[1][1]\n",
    "    y_pred = model(image); prob = torch.nn.functional.softmax(y_pred,dim=1);\n",
    "    pred_label = prob.argmax(dim=1);\n",
    "    \n",
    "    # Only display preMCI\n",
    "    if np.not_equal(label,1):\n",
    "        continue\n",
    "\n",
    "    img = image.detach().cpu().numpy()\n",
    "\n",
    "    name = \"actual: \"\n",
    "    name += \"Responder\" if np.equal(label,1) else \"Non-Responder\"\n",
    "    name += \"\\npred: \"\n",
    "    name += \"Responder\" if np.equal(pred_label.cpu().numpy(),1) else \"Non-Responder\"\n",
    "    name += f\"\\nResponder: {prob[0,1]:.3}\"\n",
    "    name += f\"\\nNon-Responder: {prob[0,0]:.3}\"\n",
    "\n",
    "    # run CAM\n",
    "    cam_result = cam(x=image, class_idx=None)\n",
    "    cam_result = cam_result\n",
    "\n",
    "    # run occlusion\n",
    "    occ_result, _ = occ_sens(x=image)\n",
    "    occ_result = occ_result[..., pred_label];\n",
    "\n",
    "    if isinstance(img, torch.Tensor):\n",
    "            img = img.cpu().detach()\n",
    "    ax = axes[0, example]\n",
    "    im_show = ax.imshow(np.squeeze(img[0][0].T), cmap=\"jet\", origin='lower')\n",
    "    ax.set_title(name, fontsize=25)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    if isinstance(cam_result, torch.Tensor):\n",
    "        cam_result = cam_result.cpu().detach()\n",
    "    ax = axes[1, example]\n",
    "    im_show = ax.imshow(np.squeeze(img[0][0].T), cmap=\"gray\", origin='lower')\n",
    "    im_show = ax.imshow(np.squeeze(cam_result[0][0].T), cmap=\"jet\", origin='lower', alpha=0.5)\n",
    "    ax.set_title(\"Grad-CAM++\", fontsize=25)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    if isinstance(occ_result, torch.Tensor):\n",
    "            occ_result = occ_result.cpu().detach()\n",
    "    ax = axes[2, example]\n",
    "    im_show = ax.imshow(np.squeeze(img[0][0].T), cmap=\"gray\", origin='lower')\n",
    "    im_show = ax.imshow(np.squeeze(occ_result[0][0].T), cmap=\"jet\", origin='lower', alpha=0.5)\n",
    "    ax.set_title(\"Occ. Sens\", fontsize=25)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    example += 1\n",
    "    if example == n_examples:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC-PyTorch-1.9",
   "language": "python",
   "name": "ngc-pytorch-1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
